{"version":3,"kind":"Notebook","sha256":"5479e7a4125e8ecf2ab395e774492bb83924e0fc3e99543d6cf3d22647211689","slug":"ctd-comparison-200-wico-copy1","location":"/CTD_comparison_200_WiCO-Copy1.ipynb","dependencies":[],"frontmatter":{"title":"Comparison of the HAFRO CTD data with ROMS model output","content_includes_title":false,"kernelspec":{"name":"roms-tools","display_name":"Python (My roms-tools Kernel)","language":"python"},"exports":[{"format":"ipynb","filename":"CTD_comparison_200_WiCO-Copy1.ipynb","url":"/CTD_comparison_200_W-23c70dce07b304bbe1bb2e6798ddff5a.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This notebook loads the observed CTD data and model data. It converts observed data to xarray format, and regrids model data onto lat,lon,z coordinates. There are some options available to reduce the model data loaded in for the sake of available memory. It then makes various plots of stratification and seasonal evolution of salinity and temperature. We use the roms-tools regridder.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"CBrenHj02C"}],"key":"LQ2x9mBXjx"}],"key":"tmBkoEmThR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Loading in modules\n\nimport subprocess\nimport os\nimport pandas as pd\nimport netCDF4\nimport numpy as np\nimport glob\nimport time\nimport matplotlib.pyplot as plt\nimport copy\n\nimport xarray as xr\nfrom datetime import datetime, timedelta \nimport dask\nfrom scipy.interpolate import griddata\n#from ocean_c_lab_tools import *\n#from celluloid import Camera \n#import PyCO2SYS as csys\n#import seawater as sw\nfrom roms_regrid import *","key":"icQI7WfLvA"},{"type":"outputs","id":"RUDc7CXKB253PDCT3wHyJ","children":[],"key":"KiBEdlrVhX"}],"key":"Ow7IIPz9vR"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Setting parameters and paths","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mHk2eCCyMR"}],"identifier":"setting-parameters-and-paths","label":"Setting parameters and paths","html_id":"setting-parameters-and-paths","implicit":true,"key":"KP0m0zCutQ"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Here, all the parameters for model regridding, the paths for data storage, and the chosen length of model comparison are set, so that the remainder of the notebook needs minimal adjustment","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"CEg1SCVJGr"}],"key":"dfUBCCDxvV"}],"key":"nlGI4hJfgM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"HAFRO_path='/home/x-uheede/R/HAFRO/Hafro_cruises.xls'\nmodel_grid_path=\"/home/x-uheede/S/Iceland2_MARBL_2024_60m/P_INPUT/Iceland2_grid_MAT1.nc\"\n# Grid parameters, only modify these if grid is made in MATLAB\nvert_levels=60\ntheta_s_model=5\ntheta_b_model=2\nhc_model=300\nmodel_data_path=\"/anvil/scratch/x-uheede/Iceland2_NOMARBL_2024_RHALF/Iceland2_MARBL_2024_his.20240[4-8]????????.nc\"\nmonths_analysis=[4,5,6,7,8] # enter the months you want to analyze for the model\n# enter the dates you want to analyze for the observations\nmonths_string_begin='01-04-2024'\nmonths_string_end='31-08-2024'\ntarget_depth_levels=[1,2,3,4,5,7,9,10,12,14,15,16,18,20,26,30,36,40,50,80] # Specify depth levels of interest\nthinner=24*7 # specify the temporal frequency of data being read (i.e. no need to read in hourly data)\n","key":"LFjfOB6V7S"},{"type":"outputs","id":"ZBvw47ZHhDK_fjR11AGAo","children":[],"key":"hXHHnCVEjU"}],"key":"z9XWfvjLSk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Read in observed data\nxls = pd.ExcelFile(HAFRO_path)\n\ncombo = pd.read_excel(xls, 'combo',decimal='.')\n\nobs=xr.Dataset.from_dataframe(combo)\n\n# reformat into xarray dataset, HV is our station number indicator\nobs=obs.set_index(index=['HV','Depth','mon/day/yr'])\nobs=obs.drop_duplicates('index')\nobs=obs.unstack('index')\n# renaming variables that have strange formatting in the excelsheet\nobs=obs.rename(name_dict={'mon/day/yr':'time','Depth':'depth','Latitude(¬∞N)':'lat','Longitude(¬∞E)':'lon'})\n","key":"diW0YHIsK4"},{"type":"outputs","id":"mBPyttmpvXqV8gzQ1Xda8","children":[],"key":"YKy9x247Sb"}],"key":"KeIZ1qwPTV"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# define location which calculations the average location of each station\ndef get_location(obs, hv_values):\n    locations = []\n    for hv in hv_values:\n        lat = obs['lat'].sel(HV=hv).isel(depth=0).mean('time').squeeze().values\n        lon = obs['lon'].sel(HV=hv).isel(depth=0).mean('time').squeeze().values + 360\n        locations.append([lat, lon])\n    return locations\n\n# List of HV values\nhv_values = range(1, 13)\n\n# Get the locations\nlocations = get_location(obs, hv_values)","key":"ibEasn5EHF"},{"type":"outputs","id":"ZGYcx8lOSbieptg4sA1Wy","children":[],"key":"d7kGruaA8y"}],"key":"GM2GcgsbSk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from roms_tools import Grid, ROMSOutput","key":"oLLFO3eEP9"},{"type":"outputs","id":"ktUg5NhSKjhSzBR1teJbW","children":[],"key":"rvadn8Kf1N"}],"key":"mKbjGkjoLq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"grid = Grid.from_file(\n    model_grid_path\n)","key":"te3qPgvO7W"},{"type":"outputs","id":"rWRCxBiza5T9lxxgzHFzZ","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"2025-12-08 13:18:27 - WARNING - Vertical coordinates (Cs_r, Cs_w) not found in grid file.\n2025-12-08 13:18:27 - INFO - === Preparing the vertical coordinate system using N = 100, theta_s = 5.0, theta_b = 2.0, hc = 300.0 ===\n2025-12-08 13:18:27 - INFO - Total time: 0.003 seconds\n2025-12-08 13:18:27 - INFO - ========================================================================================================\n"},"children":[],"key":"HpWkxSD4v6"}],"key":"oRSppTVDgG"}],"key":"n2oQmyDJW1"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#Only run this cell if grid is made in MATLAB\ngrid.update_vertical_coordinate(N=vert_levels, theta_s=theta_s_model, theta_b=theta_b_model, hc=hc_model, verbose=False)","key":"JJwGbrlofM"},{"type":"outputs","id":"q8kU8TSoCFj0aBGHr0BVv","children":[],"key":"dk02zJtx27"}],"key":"mNUheB7wlq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import xarray as xr\nimport numpy as np\n\n# Load ROMS output using your pattern\nroms_output = ROMSOutput(\n    grid=grid,\n    path=[\n        model_data_path,\n    ],\n    use_dask=True,\n)\n\nds = roms_output.regrid(var_names=[\"temp\", \"salt\"],depth_levels=target_depth_levels)\n\n# Extract month for each time entry\nmonths = ds.time.dt.month\n\n# Dimensions we want\nmonth_vals = months_analysis\ntypes = [\"mean\", \"std\"]\n\n# Create empty datasets for salt & temp\nsalt_data = []\ntemp_data = []\n\nfor m in month_vals:\n    ds_m = ds.sel(time=months == m)\n\n    # Calculate and append mean & std\n    salt_mean = ds_m[\"salt\"].thin({'time': thinner}).mean(\"time\").load()\n    salt_std  = ds_m[\"salt\"].thin({'time': thinner}).std(\"time\").load()\n    temp_mean = ds_m[\"temp\"].thin({'time': thinner}).mean(\"time\").load()\n    temp_std  = ds_m[\"temp\"].thin({'time': thinner}).std(\"time\").load()\n\n    salt_data.append(xr.concat([salt_mean, salt_std], dim=\"type\"))\n    temp_data.append(xr.concat([temp_mean, temp_std], dim=\"type\"))\n\n# Concatenate over month dimension\nsalt_all = xr.concat(salt_data, dim=\"month\")\ntemp_all = xr.concat(temp_data, dim=\"month\")\n\n# Assign coordinates\nsalt_all = salt_all.assign_coords(type=types, month=month_vals)\ntemp_all = temp_all.assign_coords(type=types, month=month_vals)\n\n# Build final dataset\nds_monthly = xr.Dataset(\n    {\n        \"salt\": salt_all,\n        \"temp\": temp_all,\n    }\n)\n\nprint(ds_monthly)\n\n","key":"xssXKDfmk5"},{"type":"outputs","id":"cwrgr6kVnYml5SXJV4k8w","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n/home/x-uheede/.conda/envs/2024.02-py311/roms-tools/lib/python3.11/site-packages/dask/array/numpy_compat.py:58: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\n"},"children":[],"key":"GBkFPsdJqV"},{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"<xarray.Dataset> Size: 555MB\nDimensions:  (lat: 481, lon: 721, depth: 20, type: 2, month: 5)\nCoordinates:\n  * lat      (lat) float32 2kB 63.0 63.0 63.01 63.01 ... 64.99 64.99 65.0 65.0\n  * lon      (lon) float32 3kB 336.0 336.0 336.0 336.0 ... 339.0 339.0 339.0\n  * depth    (depth) float32 80B 1.0 2.0 3.0 4.0 5.0 ... 36.0 40.0 50.0 80.0\n  * type     (type) <U4 32B 'mean' 'std'\n  * month    (month) int64 40B 4 5 6 7 8\nData variables:\n    salt     (month, type, lat, lon, depth) float32 277MB nan nan ... nan nan\n    temp     (month, type, lat, lon, depth) float32 277MB nan nan ... nan nan\n"},"children":[],"key":"kaa5ojM14T"}],"key":"jmNovWGjL3"}],"key":"X1YvzIr810"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"[months_analysis]","key":"ODEUlfS6RY"},{"type":"outputs","id":"40XdoXrOiusu59RP6Ld0C","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":9,"metadata":{},"data":{"text/plain":{"content":"[[4, 5, 6, 7, 8]]","content_type":"text/plain"}}},"children":[],"key":"ExjZjmRWqH"}],"key":"dCmI3De0iT"}],"key":"PbthyRBkjZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"t=ds_monthly['temp']\ns=ds_monthly['salt']","key":"dYKUdAZeka"},{"type":"outputs","id":"yWgW3XocEphGroEvdaB2F","children":[],"key":"CwAkzF84ZE"}],"key":"oL1e6SuAns"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Assuming locations is a list of lat/lon pairs\nt_values = []\ns_values = []\n# Loop over the first 10 locations and store each selection in t_values\nfor i in range(12):\n    lat, lon = locations[i]\n    \n    # Select the 't' values at the nearest lat/lon\n    t_selected = t.sel(lat=lat, method='nearest').sel(lon=lon, method='nearest')\n    s_selected = s.sel(lat=lat, method='nearest').sel(lon=lon, method='nearest')\n    \n    # Store the result in the listx\n    t_values.append(t_selected)\n    s_values.append(s_selected)\n\n# Combine the selections into an xarray Dataset or DataArray\nt_values_combined = xr.concat(t_values, dim='location')\ns_values_combined = xr.concat(s_values, dim='location')\n\n# Assign a location coordinate for clarity (optional)\nt_values_combined = t_values_combined.assign_coords(location=('location', range(1, 13)))\ns_values_combined = s_values_combined.assign_coords(location=('location', range(1, 13)))\nt_values_combined['depth']=t_values_combined.depth*(-1)\ns_values_combined['depth']=s_values_combined.depth*(-1)\n# Now you have t_values as an xarray object (Dataset or DataArray)\n#print(t_values_combined)\n","key":"kD0huJ70VK"},{"type":"outputs","id":"hAUL4J3Zo_9y4b4V0ykwn","children":[],"key":"S5THLQ02GY"}],"key":"LEvN0cbqVs"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\n\n# Set up the subplots\nfig, axarr = plt.subplots(nrows=3, ncols=4, figsize=(12, 6*1.2), constrained_layout=True)\nax = axarr.flatten()  # Flatten to make indexing easier\npalette = plt.get_cmap('tab20')\n\n# Loop through 12 locations\nfor i in range(12):\n    loc = i + 1  # location index starts at 1\n\n    # Extract model data\n    model_mean = s_values_combined.isel(type=0).mean('month').sel(location=loc)\n    model_std = s_values_combined.isel(type=1).mean('month').sel(location=loc)\n\n    # Plot model average\n    ax[i].plot(model_mean, s_values_combined.depth*(-1), label='Model Avg', color='black')\n\n    # Plot shaded region for model standard deviation\n    ax[i].fill_betweenx(s_values_combined.depth*(-1), model_mean - model_std, model_mean + model_std, \n                         color='grey', alpha=0.4, label='Model Std Dev')\n\n    # Extract observed data\n    ax[i].plot(obs['Salinity'].sel(HV=loc).dropna(dim='depth', how='all').sel(time=slice(months_string_begin, months_string_end)).mean('time'),\n            obs.sel(HV=loc).dropna(dim='depth', how='all').depth, label='Obs', color=palette(2))\n\n    obs_std = obs['Salinity'].sel(HV=loc).dropna(dim='depth', how='all').sel(time=slice(months_string_begin, months_string_end)).std('time')\n\n\n    # Plot shaded region for observed standard deviation\n    ax[i].fill_betweenx(obs.depth, (obs['Salinity'].sel(HV=loc).sel(time=slice(months_string_begin, months_string_end)).mean('time')-obs['Salinity'].sel(HV=loc).sel(time=slice(months_string_begin, months_string_end)).std('time')),(obs['Salinity'].sel(HV=loc).sel(time=slice(months_string_begin, months_string_end)).mean('time')+obs['Salinity'].sel(HV=loc).sel(time=slice(months_string_begin, months_string_end)).std('time')), color=palette(2), alpha=0.4)\n\n    # Set depth limits for specific subplots\n    ax[0].set_ylim(0,35)\n    ax[2].set_ylim(0,25)\n    ax[3].set_ylim(0,30)\n    ax[4].set_ylim(0,70)\n    ax[5].set_ylim(0,28)\n    ax[6].set_ylim(0,25)\n    ax[7].set_ylim(0,25)\n    ax[8].set_ylim(0,20)\n    ax[9].set_ylim(0,60)\n    ax[11].set_ylim(0,6)\n\n    # Set title, labels\n    ax[i].set_title(f'Salinity CTD Station: {obs.HV[loc - 1].values}')\n    ax[i].set_xlabel('psu')\n    ax[i].set_ylabel('Depth')\n\n    # Show legend only for the first subplot\n    if i == 1:\n        ax[i].legend()\n\nfor i in range(12):\n    ax[i].invert_yaxis()\n    \n# Display the plot\nplt.show()\n","key":"DKItL9oLjJ"},{"type":"outputs","id":"fHjlgZtjl8UHhAevejd8A","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"07123622f9a1fdf6d29c9486efb19ec3","path":"/07123622f9a1fdf6d29c9486efb19ec3.png"},"text/plain":{"content":"<Figure size 1200x720 with 12 Axes>","content_type":"text/plain"}}},"children":[],"key":"fdVCEA1CnT"}],"key":"rREZQEc0MY"}],"key":"EViG8gVh82"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"loc = np.array(locations)\nlevels_psu=np.arange(31,35,0.1)\nlevels_t=np.arange(2.5,10,0.2)\ndata_psu1=obs['Salinity'].sel(time=slice(months_string_begin, months_string_end)).sel(HV=[1,3,5,7,9,10,12]).mean('time')\ndata_psu2=obs['Salinity'].sel(time=slice(months_string_begin, months_string_end)).sel(HV=[2,3,4]).mean('time')\ndata_t=obs['Temperature'].sel(time=slice(months_string_begin, months_string_end)).sel(HV=[1,3,5,7,9,10,12]).mean('time')\n\nfig, axarr = plt.subplots(nrows=1, ncols=2, figsize=(6*2, 3), constrained_layout=True)\nax = axarr.flatten()\nc0=ax[0].contourf(loc[[1-1,3-1,5-1,7-1,9-1,10-1,12-1],1]-360,data_psu1.depth, data_psu1.transpose(),levels_psu)\n\n#ax[1].contourf(loc[[1-1,3-1,5-1,7-1,9-1,10-1,12-1],1]-360,data.depth, data_t.transpose(),levels_t)\n#ax[1].invert_yaxis()\nc1=ax[1].contourf(loc[[2-1,3-1,4-1],0],data_psu2.depth, data_psu2.transpose(),levels_psu)\n\nax[0].set_title('along fjord mean salinity profile (Observed)')\nax[0].set_xlabel('longitude')\nax[0].set_ylabel('depth')\nax[0].set_ylim(0,40)\nplt.colorbar(c0,ax=ax[0], orientation='vertical', label='psu',shrink=0.5)\nax[0].invert_yaxis()\n\nax[1].set_title('across fjord mean salinity profile (Observed)')\nax[1].set_xlabel('latitude')\nax[1].set_ylabel('depth')\nax[1].set_ylim(0,40)\nplt.colorbar(c1, ax=ax[1], orientation='vertical', label='psu',shrink=0.5)\nax[1].invert_yaxis()","key":"ej6o7PNoNf"},{"type":"outputs","id":"B4sOha0a8p3QPHzSxd_qe","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"85137b3361f67f0a6769fbeb9c6e9fe1","path":"/85137b3361f67f0a6769fbeb9c6e9fe1.png"},"text/plain":{"content":"<Figure size 1200x300 with 4 Axes>","content_type":"text/plain"}}},"children":[],"key":"yZbkIrhncy"}],"key":"olaVZ1b2kz"}],"key":"KrTzpYyjRf"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"loc = np.array(locations)\nlevels_psu=np.arange(31,35,0.1)\nlevels_t=np.arange(2.5,10,0.2)\ndata_psu1=s_values_combined.isel(type=0).mean('month').sel(location=[1,3,5,7,9,10,12])\ndata_psu2=s_values_combined.isel(type=0).mean('month').sel(location=[2,3,4])\n\n\n#data_t=obs['Temperature'].sel(HV=[1,3,5,7,9,10,12]).mean('time')\n\nfig, axarr = plt.subplots(nrows=1, ncols=2, figsize=(6*2, 3), constrained_layout=True)\nax = axarr.flatten()\nc0=ax[0].contourf(loc[[1-1,3-1,5-1,7-1,9-1,10-1,12-1],1]-360,data_psu1.depth*(-1), data_psu1.transpose(),levels_psu)\n\n#ax[1].contourf(loc[[1-1,3-1,5-1,7-1,9-1,10-1,12-1],1]-360,data.depth, data_t.transpose(),levels_t)\n#ax[1].invert_yaxis()\nc1=ax[1].contourf(loc[[2-1,3-1,4-1],0],data_psu2.depth*(-1), data_psu2.transpose(),levels_psu)\n\nax[0].set_title('along fjord mean salinity profile (model)')\nax[0].set_xlabel('longitude')\nax[0].set_ylabel('depth')\nax[0].set_ylim(0,40)\nplt.colorbar(c0,ax=ax[0], orientation='vertical', label='psu',shrink=0.5)\nax[0].invert_yaxis()\n\nax[1].set_title('across fjord mean salinity profile (model)')\nax[1].set_xlabel('latitude')\nax[1].set_ylabel('depth')\nax[1].set_ylim(0,40)\nplt.colorbar(c1, ax=ax[1], orientation='vertical', label='psu',shrink=0.5)\nax[1].invert_yaxis()","key":"Nw7swxTRkj"},{"type":"outputs","id":"sJu-af22Czxp8HmI-CKN4","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"6f34322a72fc4d59751a4d84d0e51841","path":"/6f34322a72fc4d59751a4d84d0e51841.png"},"text/plain":{"content":"<Figure size 1200x300 with 4 Axes>","content_type":"text/plain"}}},"children":[],"key":"NDdABnPkUU"}],"key":"wf4XwKOheK"}],"key":"JcD5Jcw2Tl"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# --- CONFIG ---\nmonth_names = [\"May\", \"June\", \"July\", \"August\", \"September\"]\nn_months = 4   # May–Sep\npalette = plt.get_cmap(\"tab20\")\n\n# --- TAKE MEAN OVER ALL 12 STATIONS ---\nmodel_mean = s_values_combined.isel(type=0).mean(dim=\"location\")\nmodel_std  = s_values_combined.isel(type=1).mean(dim=\"location\")\n\n# --- OBSERVATIONS: MEAN + STD ACROSS STATIONS ---\nobs_monthly_mean = []\nobs_monthly_std = []\n\nfor m in range(n_months):\n    month_str = f\"2024-{m+5:02d}\"   # 05–09\n    obs_sel = obs[\"Salinity\"].sel(\n        time=slice('2024-0'+str(m+4)+'-01','2024-0'+str(m+4)+'-30')\n    )\n\n    # mean over stations, then mean over time\n    obs_mean_m = obs_sel.mean(dim=\"time\").mean(dim=\"HV\")\n    obs_std_m  = obs_sel.std(dim=\"time\").mean(dim=\"HV\")\n\n    obs_monthly_mean.append(obs_mean_m)\n    obs_monthly_std.append(obs_std_m)\n\n# --- SET UP FIGURE ---\nfig, axarr = plt.subplots(\n    nrows=3, ncols=2, figsize=(5, 7), constrained_layout=True\n)\nax = axarr.flatten()\n\nfor m in range(n_months):\n\n    # MODEL DATA FOR MONTH m\n    model_mean_m = model_mean.isel(month=m+1)\n    model_std_m  = model_std.isel(month=m+1)\n\n    # OBS DATA FOR MONTH m\n    obs_mean_m = obs_monthly_mean[m]\n    obs_std_m  = obs_monthly_std[m]\n\n    # --- PLOTTING ---\n    ax[m].plot(model_mean_m, s_values_combined.depth*(-1), color='black', label=\"Model Mean\")\n    ax[m].fill_betweenx(\n        s_values_combined.depth*(-1),\n        model_mean_m - model_std_m,\n        model_mean_m + model_std_m,\n        color=\"grey\", alpha=0.4, label=\"Model Std\"\n    )\n\n    ax[m].plot(obs_mean_m, obs.sel(HV=1).depth, color=palette(3), label=\"Obs Mean\")\n    ax[m].fill_betweenx(\n        obs.sel(HV=1).depth,\n        obs_mean_m - obs_std_m,\n        obs_mean_m + obs_std_m,\n        color=palette(3), alpha=0.3, label=\"Obs Std\"\n    )\n\n    # TITLE + LABELS\n    ax[m].set_title(f\"Average Salinity Profile – {month_names[m]}\")\n    ax[m].set_xlabel(\"psu\")\n    ax[m].set_ylabel(\"Depth (m)\")\n    ax[m].set_ylim(0,40)\n    # invert depth\n    ax[m].invert_yaxis()\n\n    # legend on first panel\n    if m == 0:\n        ax[m].legend()\n\n# Remove empty subplot (6th)\nfig.delaxes(ax[5])\n\nplt.show()\n","key":"DlJX93t3Ob"},{"type":"outputs","id":"mxgCGbT2fi_BEh33Gg7tt","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"cd1d864047d765768eecd928db1d2ce1","path":"/cd1d864047d765768eecd928db1d2ce1.png"},"text/plain":{"content":"<Figure size 500x700 with 5 Axes>","content_type":"text/plain"}}},"children":[],"key":"UywnjMOMVJ"}],"key":"gG1882pnY3"}],"key":"osAqnvb2UY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# --- CONFIG ---\nmonth_names = [\"May\", \"June\", \"July\", \"August\", \"September\"]\nn_months = 4# May–Sep\npalette = plt.get_cmap(\"tab20\")\n\n# --- TAKE MEAN OVER ALL 12 STATIONS ---\nmodel_mean = t_values_combined.isel(type=0).mean(dim=\"location\")\nmodel_std  = t_values_combined.isel(type=1).mean(dim=\"location\")\n\n# --- OBSERVATIONS: MEAN + STD ACROSS STATIONS ---\nobs_monthly_mean = []\nobs_monthly_std = []\n\nfor m in range(n_months):\n    month_str = f\"2024-{m+4:02d}\"   # 05–09\n    obs_sel = obs[\"Temperature\"].sel(\n        time=slice('2024-0'+str(m+5)+'-01','2024-0'+str(m+5)+'-30')\n    )\n\n    # mean over stations, then mean over time\n    obs_mean_m = obs_sel.mean(dim=\"time\").mean(dim=\"HV\")\n    obs_std_m  = obs_sel.std(dim=\"time\").mean(dim=\"HV\")\n\n    obs_monthly_mean.append(obs_mean_m)\n    obs_monthly_std.append(obs_std_m)\n\n# --- SET UP FIGURE ---\nfig, axarr = plt.subplots(\n    nrows=3, ncols=2, figsize=(5, 7), constrained_layout=True\n)\nax = axarr.flatten()\n\nfor m in range(n_months):\n\n    # MODEL DATA FOR MONTH m\n    model_mean_m = model_mean.isel(month=m+1)\n    model_std_m  = model_std.isel(month=m+1)\n\n    # OBS DATA FOR MONTH m\n    obs_mean_m = obs_monthly_mean[m]\n    obs_std_m  = obs_monthly_std[m]\n\n    # --- PLOTTING ---\n    ax[m].plot(model_mean_m, s_values_combined.depth*(-1), color='black', label=\"Model Mean\")\n    ax[m].fill_betweenx(\n        s_values_combined.depth*(-1),\n        model_mean_m - model_std_m,\n        model_mean_m + model_std_m,\n        color=\"grey\", alpha=0.4, label=\"Model Std\"\n    )\n\n    ax[m].plot(obs_mean_m, obs.sel(HV=1).depth, color=palette(3), label=\"Obs Mean\")\n    ax[m].fill_betweenx(\n        obs.sel(HV=1).depth,\n        obs_mean_m - obs_std_m,\n        obs_mean_m + obs_std_m,\n        color=palette(3), alpha=0.3, label=\"Obs Std\"\n    )\n\n    # TITLE + LABELS\n    ax[m].set_title(f\"Average Temperature Profile – {month_names[m]}\")\n    ax[m].set_xlabel(\"degrees C\")\n    ax[m].set_ylabel(\"Depth (m)\")\n    ax[m].set_ylim(0,40)\n    # invert depth\n    ax[m].invert_yaxis()\n\n    # legend on first panel\n    if m == 0:\n        ax[m].legend()\n\n# Remove empty subplot (6th)\nfig.delaxes(ax[5])\n\nplt.show()\n","key":"Im1EDMzHwk"},{"type":"outputs","id":"Cd-FyDE9BpUKhbSUqw5gB","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"3b6b04460b6259aae08a360087037dfb","path":"/3b6b04460b6259aae08a360087037dfb.png"},"text/plain":{"content":"<Figure size 500x700 with 5 Axes>","content_type":"text/plain"}}},"children":[],"key":"RY2kzAf9dx"}],"key":"qyTMf4DJnD"}],"key":"Hd5WsHVO1S"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import xarray as xr\nimport numpy as np\n\n# Load ROMS output using your pattern\nroms_output = ROMSOutput(\n    grid=grid,\n    path=[\n        model_data_path,\n    ],\n    use_dask=True,\n)\n\nds = roms_output.regrid(var_names=[\"temp\", \"salt\"],depth_levels=[5])\n","key":"nTQBvXBjdB"},{"type":"outputs","id":"b7YbZoyb5fQCTktu__zg-","children":[],"key":"kd7XmqwJ3D"}],"key":"MYvgNQJphz"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"t=ds['temp'].thin({'time': 24}).load()\ns=ds['salt'].thin({'time': 24}).load()","key":"ELRSheB4ee"},{"type":"outputs","id":"3cR6KA2ZBQVaXcqbebz4r","children":[],"key":"KgzOaRIEex"}],"key":"dXVPQvTEgz"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Define file paths and station names\nstations = [\"HVIN_1\", \"HVNA_1\", \"HVNV_1\", \"HVSA_1\", \"HVSV_1\"]\nfile_paths = {name: f\"/global/cfs/cdirs/m4632/uheede/Hafro_obsdata/{name}new.nc\" for name in stations}\n# Define file paths and station names\nstations = [\"HVIN_1\", \"HVNA_1\", \"HVNV_1\", \"HVSA_1\", \"HVSV_1\"]\nfile_paths = {name: f\"/home/x-uheede/R/HAFRO/{name}_TS.nc\" for name in stations}\n\n# Dictionary to store datasets\ndatasets = {}\n\nfor name, path in file_paths.items():\n    ds = xr.open_dataset(path)\n    \n    # Store dataset with adjusted longitude\n    datasets[name] = ds.assign_coords(lon=ds['lon'].load() + 360)\n\nsubtract = 739674 - 9189  # Computed constant\nreference_date = pd.to_datetime(\"2000-01-01\")  # Reference date\n\n# Apply transformation to all datasets\nfor name, ds in datasets.items():\n    datetime_series = reference_date + pd.to_timedelta((ds['time'].values - subtract), unit='D')\n    datasets[name] = ds.assign_coords(time_dim=datetime_series)  # Update the time coordinate\n\nds_list = []\n\nfor name, ds in datasets.items():\n    # Add station as a new dimension\n    ds_expanded = ds.expand_dims(station=[name])\n    ds_list.append(ds_expanded)\n    \ncombined = xr.concat(ds_list, dim=\"station\")\nmean_ts = combined.mean(dim=\"station\", skipna=True)","key":"LV3VgcPA4i"},{"type":"outputs","id":"ewsgD0bNJWphg9vOpC1zf","children":[],"key":"YO4W7PMGdT"}],"key":"SjXhniSkLA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"plt.plot(mean_ts['temperature'])","key":"tbaTHNBZBg"},{"type":"outputs","id":"-ugqh-C4E5E5-fiXPcmqn","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"636e22ffc8e490fd2dbeba7e3e690e78","path":"/636e22ffc8e490fd2dbeba7e3e690e78.png"},"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"ZuApius1vp"}],"key":"sZJuXkl8f9"}],"key":"aufV65vyBV"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Assuming locations is a list of lat/lon pairs\nt_values = []\ns_values = []\n# Loop over the first 10 locations and store each selection in t_values\nfor i in range(12):\n    lat, lon = locations[i]\n    \n    # Select the 't' values at the nearest lat/lon\n    t_selected = t.sel(lat=lat, method='nearest').sel(lon=lon, method='nearest')\n    s_selected = s.sel(lat=lat, method='nearest').sel(lon=lon, method='nearest')\n    \n    # Store the result in the listx\n    t_values.append(t_selected)\n    s_values.append(s_selected)\n\n# Combine the selections into an xarray Dataset or DataArray\nt_values_combined = xr.concat(t_values, dim='location')\ns_values_combined = xr.concat(s_values, dim='location')\n\n# Assign a location coordinate for clarity (optional)\nt_values_combined = t_values_combined.assign_coords(location=('location', range(1, 13)))\ns_values_combined = s_values_combined.assign_coords(location=('location', range(1, 13)))\n#t_values_combined['depth']=t_values_combined.depth*(-1)\n#s_values_combined['depth']=s_values_combined.depth*(-1)\n# Now you have t_values as an xarray object (Dataset or DataArray)\n#print(t_values_combined)\n","key":"WNaQdA0Jei"},{"type":"outputs","id":"ar5blJW0IeuBjK14OPsdS","children":[],"key":"AsvtT5AIfO"}],"key":"M0AAnCwCNQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\n\n# Set up the subplots\nfig, axarr = plt.subplots(nrows=2, ncols=4, figsize=(12, 4*1.2), constrained_layout=True)\nax = axarr.flatten()  # Flatten to make indexing easier\npalette = plt.get_cmap('tab20')\n\n# Plot observed salinity for May 2024\nax[1].plot(mean_ts['salinity'].time_dim.sel(time_dim=slice('04-01-2024', '09-01-2024')),\n           mean_ts['salinity'].sel(time_dim=slice('04-01-2024', '09-01-2024')),\n           label='May', color=palette(2))\n\nax[0].plot(s_values_combined.time, s_values_combined.sel(location=[1,3,4,5,6,7,8,9,10,12]).mean('location'),\n           label='May', color=palette(1))\n\n# Plot observed salinity for May 2024\nax[3].plot(mean_ts['temperature'].time_dim.sel(time_dim=slice('04-01-2024', '09-01-2024')),\n           mean_ts['temperature'].sel(time_dim=slice('04-01-2024', '09-01-2024')),\n           label='May', color=palette(2))\nax[3].set_ylim(2,12.5)\n\nax[2].plot(s_values_combined.time, t_values_combined.sel(location=[1,3,4,5,6,7,8,9,10,12]).mean('location'),\n           label='May', color=palette(1))\nax[2].set_ylim(2,12.5)\nax[5].plot(datasets['HVSV_1'].time_dim.sel(time_dim=slice('04-01-2024', '09-01-2024')),\n           datasets['HVSV_1']['salinity'].sel(time_dim=slice('04-01-2024', '09-01-2024')),\n           label='May', color=palette(2))\n\nax[4].plot(s_values_combined.time, s_values_combined.sel(location=[1]).mean('location'),\n           label='May', color=palette(1))\n\n# Plot observed salinity for May 2024\nax[7].plot(datasets['HVSV_1'].time_dim.sel(time_dim=slice('04-01-2024', '09-01-2024')),\n           datasets['HVSV_1']['temperature'].sel(time_dim=slice('04-01-2024', '09-01-2024')),\n           label='May', color=palette(2))\nax[7].set_ylim(2,12.5)\nax[6].plot(s_values_combined.time, t_values_combined.sel(location=[1]).mean('location'),\n           label='May', color=palette(1))\nax[6].set_ylim(2,12.5)\n# Rotate x-axis labels for all subplots\nfor a in ax:\n    a.tick_params(axis='x', rotation=45)  # Adjust rotation angle as needed\n    \n    \nax[0].set_title('salinity for all stations,\\n 5 m depth MODEL')\nax[1].set_title('salinity for all stations,\\n 5 m depth OBS')\nax[2].set_title('temperature for all stations,\\n 5 m depth MODEL')\nax[3].set_title('temperate for all stations,\\n 5 m depth OBS')\nax[4].set_title('salinity for station 1,\\n 5 m depth MODEL')\nax[5].set_title('salinity for station 1,\\n 5 m depth OBS')\nax[6].set_title('temperature for station 1,\\n 5 m depth MODEL')\nax[7].set_title('temperate for station 1,\\n 5 m depth OBS')\nplt.show()\n\n","key":"xlYRJ89ahL"},{"type":"outputs","id":"PAAGdAE5c6SizUvt3z61o","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"eb72cb6c5e1dd0ea5f58006d0a857fde","path":"/eb72cb6c5e1dd0ea5f58006d0a857fde.png"},"text/plain":{"content":"<Figure size 1200x480 with 8 Axes>","content_type":"text/plain"}}},"children":[],"key":"sSuMpzbTO0"}],"key":"O5HIntm7Y2"}],"key":"FHUKng6UKh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\n\n# Set up the subplots\nfig, axarr = plt.subplots(nrows=2, ncols=4, figsize=(12, 4*1.2), constrained_layout=True)\nax = axarr.flatten()  # Flatten to make indexing easier\npalette = plt.get_cmap('tab20')\n\n# Plot observed salinity for May 2024\nax[1].plot(obs.time.sel(time=slice('04-01-2024', '09-01-2024')),\n           obs['Salinity'].sel(depth=slice(2,5)).mean('depth').sel(HV=[1,3,4,5,6,7,8,9,10,12]).sel(time=slice('04-01-2024', '09-01-2024')).mean('HV'),\n           label='May', color=palette(2))\n\nax[0].plot(s_values_combined.time, s_values_combined.sel(location=[1,3,4,5,6,7,8,9,10,12]).mean('location'),\n           label='May', color=palette(1))\n\n# Plot observed salinity for May 2024\nax[3].plot(obs.time.sel(time=slice('04-01-2024', '09-01-2024')),\n           obs['Temperature'].sel(depth=slice(2,5)).mean('depth').sel(HV=[1,3,4,5,6,7,8,9,10,12]).sel(time=slice('04-01-2024', '09-01-2024')).mean('HV'),\n           label='May', color=palette(2))\nax[3].set_ylim(4.5,12.5)\n\nax[2].plot(s_values_combined.time, t_values_combined.sel(location=[1,3,4,5,6,7,8,9,10,12]).mean('location'),\n           label='May', color=palette(1))\nax[2].set_ylim(4.5,12.5)\nax[5].plot(obs.time.sel(time=slice('04-01-2024', '09-01-2024')),\n           obs['Salinity'].sel(depth=slice(2,5)).mean('depth').sel(HV=[1]).sel(time=slice('04-01-2024', '09-01-2024')).mean('HV'),\n           label='May', color=palette(2))\n\nax[4].plot(s_values_combined.time, s_values_combined.sel(location=[1]).mean('location'),\n           label='May', color=palette(1))\n\n# Plot observed salinity for May 2024\nax[7].plot(obs.time.sel(time=slice('04-01-2024', '09-01-2024')),\n           obs['Temperature'].sel(depth=slice(2,5)).mean('depth').sel(HV=[1]).sel(time=slice('04-01-2024', '09-01-2024')).mean('HV'),\n           label='May', color=palette(2))\nax[7].set_ylim(4.5,12.5)\nax[6].plot(s_values_combined.time, t_values_combined.sel(location=[1]).mean('location'),\n           label='May', color=palette(1))\nax[6].set_ylim(4.5,12.5)\n# Rotate x-axis labels for all subplots\nfor a in ax:\n    a.tick_params(axis='x', rotation=45)  # Adjust rotation angle as needed\n    \n    \nax[0].set_title('salinity for all stations,\\n 5 m depth MODEL')\nax[1].set_title('salinity for all stations,\\n 5 m depth OBS')\nax[2].set_title('temperature for all stations,\\n 5 m depth MODEL')\nax[3].set_title('temperate for all stations,\\n 5 m depth OBS')\nax[4].set_title('salinity for station 1,\\n 5 m depth MODEL')\nax[5].set_title('salinity for station 1,\\n 5 m depth OBS')\nax[6].set_title('temperature for station 1,\\n 5 m depth MODEL')\nax[7].set_title('temperate for station 1,\\n 5 m depth OBS')\nplt.show()\n\n","key":"p0p6m1hX3U"},{"type":"outputs","id":"wpsIfkbtlQexmnoxDsxzf","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"0a515dee162b64b472b5ee545ab6215b","path":"/0a515dee162b64b472b5ee545ab6215b.png"},"text/plain":{"content":"<Figure size 1200x480 with 8 Axes>","content_type":"text/plain"}}},"children":[],"key":"v2UEkxAKIv"}],"key":"hDqs4UdK3A"}],"key":"TvmU2fvsnY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"s_values_combined","key":"Nj8ueF5ZUm"},{"type":"outputs","id":"UZhYbAXwV4-UvqtdDhEAH","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":24,"metadata":{},"data":{"text/html":{"content_type":"text/html","hash":"45fb657ce5b8f9cdca9f313ee0840dc1","path":"/45fb657ce5b8f9cdca9f313ee0840dc1.html"},"text/plain":{"content":"<xarray.DataArray 'salt' (location: 12, time: 149, depth: 1)> Size: 14kB\narray([[[34.52833614],\n        [34.56787777],\n        [34.51707079],\n        ...,\n        [34.79924007],\n        [34.72176789],\n        [34.76371716]],\n\n       [[34.08512071],\n        [34.29611693],\n        [34.52090336],\n        ...,\n        [34.65663521],\n        [34.59649314],\n        [34.40510693]],\n\n       [[34.28148851],\n        [34.52704327],\n        [34.22031571],\n        ...,\n...\n        ...,\n        [34.04473831],\n        [33.89340926],\n        [33.61652775]],\n\n       [[33.78195849],\n        [33.4926551 ],\n        [33.66630354],\n        ...,\n        [34.0030163 ],\n        [33.89813124],\n        [33.46119242]],\n\n       [[32.81748323],\n        [33.54255016],\n        [33.90457432],\n        ...,\n        [31.7123206 ],\n        [31.82208258],\n        [33.92552031]]], shape=(12, 149, 1))\nCoordinates:\n  * time      (time) datetime64[ns] 1kB 2024-04-01T12:00:00 ... 2024-08-26T19...\n    lat       (location) float32 48B 64.27 64.29 64.3 ... 64.38 64.39 64.36\n    lon       (location) float32 48B 338.0 338.1 338.1 ... 338.5 338.5 338.6\n  * depth     (depth) float32 4B 5.0\n  * location  (location) int64 96B 1 2 3 4 5 6 7 8 9 10 11 12\nAttributes:\n    long_name:  salinity\n    units:      PSU","content_type":"text/plain"}}},"children":[],"key":"qkjWf7Eg4f"}],"key":"LFMhEIiFoz"}],"key":"iDV7mJR67e"}],"key":"fbDVrAaA8p"},"references":{"cite":{"order":[],"data":{}}}}